{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALLATIONS"
      ],
      "metadata": {
        "id": "gq4JhNEZITPX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq8SMVdUIPWC"
      },
      "outputs": [],
      "source": [
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS"
      ],
      "metadata": {
        "id": "NMEWtUsvIWjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sympy import N, symbols, sympify\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import lightning as pl"
      ],
      "metadata": {
        "id": "_EEjgdW7IXUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING LOOP"
      ],
      "metadata": {
        "id": "IHRWrw-0IaEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## T5 INITIALIZATION"
      ],
      "metadata": {
        "id": "4T9SnV8zIcky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "  def __init__(self, hparams, train_data, val_data):\n",
        "    super(T5FineTuner, self).__init__()\n",
        "    self.save_hyperparameters(hparams)\n",
        "    self.train_dataset = train_data\n",
        "    self.val_dataset = val_data\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "    self.model.train()\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "\n",
        "  def is_logger(self):\n",
        "    return self.trainer.global_rank <= 0\n",
        "\n",
        "  def forward(\n",
        "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n",
        "  ):\n",
        "    return self.model(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        labels = labels,\n",
        "    )\n",
        "\n",
        "  def _step(self, batch):\n",
        "    labels = batch[\"target_ids\"].clone()\n",
        "    labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"source_ids\"],\n",
        "        attention_mask=batch[\"source_mask\"],\n",
        "        labels= labels,\n",
        "        decoder_attention_mask=batch['target_mask']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "    return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      input_ids = batch[\"source_ids\"]\n",
        "      attention_mask = batch[\"source_mask\"]\n",
        "      labels = batch[\"target_ids\"]\n",
        "\n",
        "      outputs = self.model(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask,\n",
        "          labels=labels\n",
        "      )\n",
        "      loss = outputs.loss\n",
        "\n",
        "      self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "      return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    self.model.eval()\n",
        "    loss = self._step(batch)\n",
        "    tensorboard_logs = {\"val_loss\": loss}\n",
        "\n",
        "    self.log(\"val_loss\", loss)\n",
        "    return {\"val_loss\": loss}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": self.hparams.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    self.opt = optimizer\n",
        "    return [optimizer]\n",
        "\n",
        "  def optimizer_step(self, epoch=None, batch_idx=None, optimizer=None, optimizer_closure=None,):\n",
        "    optimizer.step(optimizer_closure)\n",
        "    optimizer.zero_grad()\n",
        "    self.lr_scheduler.step()\n",
        "\n",
        "  def get_tqdm_dict(self):\n",
        "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "    return tqdm_dict\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = self.train_dataset\n",
        "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
        "    t_total = (\n",
        "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "        // self.hparams.gradient_accumulation_steps\n",
        "        * float(self.hparams.num_train_epochs)\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    self.lr_scheduler = scheduler\n",
        "    return dataloader\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = self.val_dataset\n",
        "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Validation results *****\")\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "      # Log results\n",
        "      for key in sorted(metrics):\n",
        "        if key not in [\"log\", \"progress_bar\"]:\n",
        "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "          print(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "class PredictionCallback(pl.Callback):\n",
        "    def __init__(self, tokenizer, example_text):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.example_text = example_text\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        print(f\"\\n[Callback] Epoch {trainer.current_epoch}\\n\")\n",
        "\n",
        "        pl_module.model.eval()\n",
        "\n",
        "        input_ids = self.tokenizer(\n",
        "            self.example_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=100\n",
        "        ).input_ids.to(pl_module.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ids = pl_module.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                max_length=30,\n",
        "                do_sample=False,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')"
      ],
      "metadata": {
        "id": "IUVuXl2zIeKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA UPLOAD AND CLEANING"
      ],
      "metadata": {
        "id": "I5QBJ6dkIg26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train_answerextracted.csv')\n",
        "val_df = pd.read_csv('validation_answerextracted.csv')\n",
        "test_df = pd.read_csv('test_answerextracted.csv')\n",
        "\n",
        "def insert_spaces(formula):\n",
        "    if not isinstance(formula, str):\n",
        "        return formula\n",
        "    return re.sub(r'([(),])', r' \\1 ', formula).replace(\"  \", \" \").strip()\n",
        "\n",
        "\n",
        "def remove_const(expression):\n",
        "    return re.sub(r'const_([-0-9_.]+)', r'\\1', expression)\n",
        "\n",
        "ops = ['add', 'subtract', 'multiply', 'divide', 'power', 'sqrt', 'log', 'choose', 'speed',\n",
        "       'volume_rectangular_prism', 'square_area', 'circle_area', 'circumface']\n",
        "\n",
        "def fuse_operator_parens(expression, operators):\n",
        "    for op in operators:\n",
        "        expression = re.sub(rf'\\b{op}\\s*\\(', f'{op}(', expression)\n",
        "    return expression\n",
        "\n",
        "train_df['annotated_formula'] = train_df['annotated_formula'].apply(insert_spaces)\n",
        "val_df['annotated_formula'] = val_df['annotated_formula'].apply(insert_spaces)\n",
        "test_df['annotated_formula'] = test_df['annotated_formula'].apply(insert_spaces)\n",
        "\n",
        "train_df['annotated_formula'] = train_df['annotated_formula'].apply(remove_const)\n",
        "val_df['annotated_formula'] = val_df['annotated_formula'].apply(remove_const)\n",
        "test_df['annotated_formula'] = test_df['annotated_formula'].apply(remove_const)\n",
        "\n",
        "train_df['annotated_formula'] = train_df['annotated_formula'].apply(lambda x: fuse_operator_parens(x, ops))\n",
        "val_df['annotated_formula'] = val_df['annotated_formula'].apply(lambda x: fuse_operator_parens(x, ops))\n",
        "test_df['annotated_formula'] = test_df['annotated_formula'].apply(lambda x: fuse_operator_parens(x, ops))\n",
        "\n",
        "train_df['count'] = train_df[\"annotated_formula\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "train_df = train_df[train_df[\"count\"] <= 30]\n",
        "train_df['count2'] = train_df[\"Problem\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "train_df = train_df[train_df[\"count2\"] <= 100]\n",
        "\n",
        "val_df['count'] = val_df[\"annotated_formula\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "val_df = val_df[val_df[\"count\"] <= 30]\n",
        "val_df['count2'] = val_df[\"Problem\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "val_df = val_df[val_df[\"count2\"] <= 100]\n",
        "\n",
        "test_df['count'] = test_df[\"annotated_formula\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "test_df = test_df[test_df[\"count\"] <= 30]\n",
        "test_df['count2'] = test_df[\"Problem\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "test_df = test_df[test_df[\"count2\"] <= 100]\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "rdM7f8AEIhSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATE DATASET"
      ],
      "metadata": {
        "id": "K5RISgTaIjjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SATDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data,  max_len=100):\n",
        "    self.data_column = \"Problem\"\n",
        "    self.class_column = \"annotated_formula\"\n",
        "    self.data = data\n",
        "\n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    self._build()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze(0)\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze(0)\n",
        "\n",
        "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze(0)\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze(0)\n",
        "\n",
        "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "\n",
        "  def _build(self):\n",
        "    for idx in range(len(self.data)):\n",
        "      input_, target = self.data.loc[idx, self.data_column], self.data.loc[idx, self.class_column]\n",
        "\n",
        "      input_ = input_ + ' '\n",
        "      target = target + \" \"\n",
        "\n",
        "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "          [input_], max_length=self.max_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "      )\n",
        "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "          [target], max_length=30, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "      )\n",
        "      self.inputs.append(tokenized_inputs)\n",
        "      self.targets.append(tokenized_targets)\n",
        "\n",
        "train_dataset = SATDataset(tokenizer, train_df)\n",
        "val_dataset = SATDataset(tokenizer, val_df)"
      ],
      "metadata": {
        "id": "9P9I294wIj5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ARGUMENTS"
      ],
      "metadata": {
        "id": "Y_zij3vXImjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Experiments have gone on since our best model, so these parameters may not be optimal. Model is saved to cloud and can be run by itself in later section\n",
        "\n",
        "args_dict = dict(\n",
        "    model_name_or_path='google/flan-t5-base',\n",
        "    tokenizer_name_or_path='google/flan-t5-base',\n",
        "    max_seq_length=100,\n",
        "    learning_rate=8e-5,\n",
        "    weight_decay=0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=32,\n",
        "    eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    gradient_accumulation_steps=2,\n",
        "    n_gpu=1,\n",
        "    early_stop_callback=False,\n",
        "    seed=42,\n",
        "    output_dir=\"t5_sat_generator\",\n",
        ")\n",
        "args = argparse.Namespace(**args_dict)\n",
        "\n",
        "checkpoint_callback = pl.pytorch.callbacks.ModelCheckpoint(\n",
        "    dirpath=args.output_dir, filename=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5, save_last=True\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args_dict[\"gradient_accumulation_steps\"],\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    max_epochs=args_dict[\"num_train_epochs\"],\n",
        "    precision=32,\n",
        "    gradient_clip_val=1.0,\n",
        "    log_every_n_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "b8rvKMrBIm2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL TRAINING"
      ],
      "metadata": {
        "id": "NP0EVOlVIoC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5FineTuner(args, train_dataset, val_dataset)\n",
        "\n",
        "train_params[\"callbacks\"] = [LoggingCallback(), checkpoint_callback]\n",
        "\n",
        "trainer = pl.Trainer(**train_params)\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "ucXiemd2IqV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL EVALUATION"
      ],
      "metadata": {
        "id": "sxlfF-LYK8aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_output_formula(model, tokenizer, problems, batch_size=32):\n",
        "    results = []\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for i in range(0, len(problems), batch_size):\n",
        "        batch = problems[i:i + batch_size]\n",
        "        inputs = tokenizer(batch.tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ids = model.model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=100,\n",
        "                min_length=10,\n",
        "                do_sample=False,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        decoded_outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "        results.extend(decoded_outputs)\n",
        "\n",
        "    return results\n",
        "\n",
        "testcopy_df = test_df.sample(n=100, random_state=1).reset_index(drop=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.model.to(torch.float32)\n",
        "\n",
        "testcopy_df['prediction'] = batch_output_formula(model, tokenizer, testcopy_df['Problem'])"
      ],
      "metadata": {
        "id": "C9kWIvA4K-hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## METRICS"
      ],
      "metadata": {
        "id": "KfNBIFyVLfpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_levenshtein(pred, truth):\n",
        "    ratio = SequenceMatcher(None, pred, truth).ratio()\n",
        "    return ratio\n",
        "\n",
        "testcopy_df['score'] = testcopy_df.apply(lambda x: normalized_levenshtein(x['prediction'], x['annotated_formula']), axis=1)\n",
        "print(testcopy_df['score'].mean())"
      ],
      "metadata": {
        "id": "ZV9tuwFXLhAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLOSE ANSWERS"
      ],
      "metadata": {
        "id": "6FKdU8yYLj2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_df = testcopy_df[testcopy_df['score'] >= 0.9][['Problem', 'annotated_formula', 'prediction', 'score']]\n",
        "high_df.head(10)"
      ],
      "metadata": {
        "id": "4SF4TC3sLmkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SYMPY"
      ],
      "metadata": {
        "id": "pae6aIj2LrdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "const_100 = symbols('const_100')\n",
        "\n",
        "def evaluate_functional_expression(expr_str):\n",
        "    stack = []\n",
        "    num_buffer = \"\"\n",
        "    i = 0\n",
        "    while i < len(expr_str):\n",
        "        char = expr_str[i]\n",
        "\n",
        "        if char.isalnum() or char == '.':\n",
        "            num_buffer += char\n",
        "        elif char == \"_\":\n",
        "            num_buffer += '.'\n",
        "        elif char == \"(\":\n",
        "            if num_buffer:\n",
        "                if num_buffer.startswith(\"const_\"):\n",
        "                    const_value = num_buffer.replace(\"const_\", \"\").replace(\"_\", \".\")\n",
        "                    stack.append(const_value)\n",
        "                else:\n",
        "                    stack.append(num_buffer)\n",
        "                num_buffer = \"\"\n",
        "\n",
        "        elif char == \",\" or char == \")\":\n",
        "            if num_buffer:\n",
        "                if num_buffer.startswith(\"const_\"):\n",
        "                    const_value = num_buffer.replace(\"const_\", \"\").replace(\"_\", \".\")\n",
        "                    stack.append(const_value)\n",
        "                else:\n",
        "                    stack.append(num_buffer)\n",
        "                num_buffer = \"\"\n",
        "\n",
        "            if char == \")\":\n",
        "                args = []\n",
        "                while stack and stack[-1] not in {\"add\", \"subtract\", \"multiply\", \"divide\"}:\n",
        "                    args.append(stack.pop())\n",
        "                args.reverse()\n",
        "\n",
        "                if stack:\n",
        "                    func = stack.pop()\n",
        "                    if func == \"add\":\n",
        "                        result = f\"({args[0]} + {args[1]})\"\n",
        "                    elif func == \"subtract\":\n",
        "                        result = f\"({args[0]} - {args[1]})\"\n",
        "                    elif func == \"multiply\":\n",
        "                        result = f\"({args[0]} * {args[1]})\"\n",
        "                    elif func == \"divide\":\n",
        "                        result = f\"({args[0]} / {args[1]})\"\n",
        "                    stack.append(result)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return stack[0] if stack else \"\"\n",
        "\n",
        "\n",
        "def check_answer_numeric(x):\n",
        "    try:\n",
        "        math_expr = evaluate_functional_expression(x)\n",
        "        sympy_expr = sympify(math_expr, locals={'const_100': 100})\n",
        "        return sympy_expr.simplify()\n",
        "    except Exception as e:\n",
        "        return"
      ],
      "metadata": {
        "id": "TiI9i0srLscn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ACCURACY"
      ],
      "metadata": {
        "id": "XXwPwhlLLt53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testcopy_df['pred_ans'] = testcopy_df['prediction'].apply(lambda x: check_answer_numeric(x))\n",
        "def is_close(pred, truth, rtol=1e-5, atol=1e-1):\n",
        "    try:\n",
        "        if pred is None or truth is None:\n",
        "            return False\n",
        "        return np.isclose(float(N(pred)), float(N(truth)), rtol=rtol, atol=atol)\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "testcopy_df['is_close'] = testcopy_df.apply(lambda row: is_close(row['pred_ans'], row['answer_numeric']), axis=1)\n",
        "testing = testcopy_df[testcopy_df['pred_ans'].notna()]\n",
        "\n",
        "print(\"Accuracy:\", np.round(testing['is_close'].mean(), 2))"
      ],
      "metadata": {
        "id": "kWJ50zGRLvDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}