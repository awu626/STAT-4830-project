{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS"
      ],
      "metadata": {
        "id": "CH0OV3m2QgOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from difflib import SequenceMatcher\n",
        "from sympy import N, symbols, sympify\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer"
      ],
      "metadata": {
        "id": "cmlZ-u4KJMbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OUR MODEL"
      ],
      "metadata": {
        "id": "0BFPsLUhUhdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING (FROM HUGGINGFACE)"
      ],
      "metadata": {
        "id": "R9ZpwnQCVYA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The model is stored on HuggingFace due to large size\n",
        "\n",
        "model_fromhf = \"andrewyw/mathsolverprelim\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_fromhf)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_fromhf)"
      ],
      "metadata": {
        "id": "7k-hHNX5UirM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPARE TEST SET"
      ],
      "metadata": {
        "id": "tOzCOlRHJh-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "test_df = pd.read_csv('test_answerextracted.csv')\n",
        "\n",
        "def insert_spaces(formula):\n",
        "    if not isinstance(formula, str):\n",
        "        return formula\n",
        "    return re.sub(r'([(),])', r' \\1 ', formula).replace(\"  \", \" \").strip()\n",
        "\n",
        "\n",
        "def remove_const(expression):\n",
        "    return re.sub(r'const_([-0-9_.]+)', r'\\1', expression)\n",
        "\n",
        "ops = ['add', 'subtract', 'multiply', 'divide', 'power', 'sqrt', 'log', 'choose', 'speed',\n",
        "       'volume_rectangular_prism', 'square_area', 'circle_area', 'circumface']\n",
        "\n",
        "def fuse_operator_parens(expression, operators):\n",
        "    for op in operators:\n",
        "        expression = re.sub(rf'\\b{op}\\s*\\(', f'{op}(', expression)\n",
        "    return expression\n",
        "\n",
        "test_df['annotated_formula'] = test_df['annotated_formula'].apply(insert_spaces)\n",
        "test_df['annotated_formula'] = test_df['annotated_formula'].apply(remove_const)\n",
        "test_df['annotated_formula'] = test_df['annotated_formula'].apply(lambda x: fuse_operator_parens(x, ops))\n",
        "test_df['count'] = test_df[\"annotated_formula\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "test_df = test_df[test_df[\"count\"] <= 30]\n",
        "test_df['count2'] = test_df[\"Problem\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
        "test_df = test_df[test_df[\"count2\"] <= 100]\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DlPtYTPKJjOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-L CLOSENESS FORMULA"
      ],
      "metadata": {
        "id": "XvDvg-CQVyE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_levenshtein(pred, truth):\n",
        "    ratio = SequenceMatcher(None, pred, truth).ratio()\n",
        "    return ratio"
      ],
      "metadata": {
        "id": "IGRhJjqhV1v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREDICTIONS"
      ],
      "metadata": {
        "id": "Ejk6EWaDVemy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_output_formula_pretrained(model, tokenizer, problems, batch_size=32):\n",
        "    results = []\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for i in range(0, len(problems), batch_size):\n",
        "        batch = problems[i:i + batch_size]\n",
        "        inputs = tokenizer(batch.tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ids = model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=100,\n",
        "                min_length=10,\n",
        "                do_sample=False,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        decoded_outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "        results.extend(decoded_outputs)\n",
        "\n",
        "    return results\n",
        "\n",
        "testcopy_df = test_df.sample(n = 100, random_state=1).reset_index(drop=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(torch.float32)\n",
        "model.eval()\n",
        "\n",
        "testcopy_df['prediction'] = batch_output_formula_pretrained(model, tokenizer, testcopy_df['Problem'])"
      ],
      "metadata": {
        "id": "s_-Bnk9qUzHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## METRICS"
      ],
      "metadata": {
        "id": "VhuHX-jRV8Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testcopy_df['score'] = testcopy_df.apply(lambda x: normalized_levenshtein(x['prediction'], x['annotated_formula']), axis=1)\n",
        "print(testcopy_df['score'].mean())"
      ],
      "metadata": {
        "id": "KsMT9db8U60D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXEMPLIFICATION OF QUESTIONS THAT WORKED WELL"
      ],
      "metadata": {
        "id": "FntGJo9NWEZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_df = testcopy_df[testcopy_df['score'] >= 0.9][['Problem', 'annotated_formula', 'prediction', 'score']]\n",
        "high_df.head(10)"
      ],
      "metadata": {
        "id": "s6FnvPfiWHPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXEMPLIFICATION OF QUESTIONS THAT DID NOT WORK WELL"
      ],
      "metadata": {
        "id": "GAK3Ms9bWNN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_df = testcopy_df[testcopy_df['score'] < 0.5][['Problem', 'annotated_formula', 'prediction', 'score']]\n",
        "low_df.head(10)"
      ],
      "metadata": {
        "id": "EUd4MgzSWPhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SYMPY"
      ],
      "metadata": {
        "id": "UL50ey2UdmCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "const_100 = symbols('const_100')\n",
        "\n",
        "def evaluate_functional_expression(expr_str):\n",
        "    stack = []\n",
        "    num_buffer = \"\"\n",
        "    i = 0\n",
        "    while i < len(expr_str):\n",
        "        char = expr_str[i]\n",
        "\n",
        "        if char.isalnum() or char == '.':\n",
        "            num_buffer += char\n",
        "        elif char == \"_\":\n",
        "            num_buffer += '.'\n",
        "        elif char == \"(\":\n",
        "            if num_buffer:\n",
        "                if num_buffer.startswith(\"const_\"):\n",
        "                    const_value = num_buffer.replace(\"const_\", \"\").replace(\"_\", \".\")\n",
        "                    stack.append(const_value)\n",
        "                else:\n",
        "                    stack.append(num_buffer)\n",
        "                num_buffer = \"\"\n",
        "\n",
        "        elif char == \",\" or char == \")\":\n",
        "            if num_buffer:\n",
        "                if num_buffer.startswith(\"const_\"):\n",
        "                    const_value = num_buffer.replace(\"const_\", \"\").replace(\"_\", \".\")\n",
        "                    stack.append(const_value)\n",
        "                else:\n",
        "                    stack.append(num_buffer)\n",
        "                num_buffer = \"\"\n",
        "\n",
        "            if char == \")\":\n",
        "                args = []\n",
        "                while stack and stack[-1] not in {\"add\", \"subtract\", \"multiply\", \"divide\"}:\n",
        "                    args.append(stack.pop())\n",
        "                args.reverse()\n",
        "\n",
        "                if stack:\n",
        "                    func = stack.pop()\n",
        "                    if func == \"add\":\n",
        "                        result = f\"({args[0]} + {args[1]})\"\n",
        "                    elif func == \"subtract\":\n",
        "                        result = f\"({args[0]} - {args[1]})\"\n",
        "                    elif func == \"multiply\":\n",
        "                        result = f\"({args[0]} * {args[1]})\"\n",
        "                    elif func == \"divide\":\n",
        "                        result = f\"({args[0]} / {args[1]})\"\n",
        "                    stack.append(result)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return stack[0] if stack else \"\"\n",
        "\n",
        "\n",
        "def check_answer_numeric(x):\n",
        "    try:\n",
        "        math_expr = evaluate_functional_expression(x)\n",
        "        sympy_expr = sympify(math_expr, locals={'const_100': 100})\n",
        "        return sympy_expr.simplify()\n",
        "    except Exception as e:\n",
        "        return"
      ],
      "metadata": {
        "id": "p_0HAba4dm8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testcopy_df['pred_ans'] = testcopy_df['prediction'].apply(lambda x: check_answer_numeric(x))\n",
        "def is_close(pred, truth, rtol=1e-5, atol=1e-1):\n",
        "    try:\n",
        "        if pred is None or truth is None:\n",
        "            return False\n",
        "        return np.isclose(float(N(pred)), float(N(truth)), rtol=rtol, atol=atol)\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "testcopy_df['is_close'] = testcopy_df.apply(lambda row: is_close(row['pred_ans'], row['answer_numeric']), axis=1)\n",
        "testing = testcopy_df[testcopy_df['pred_ans'].notna()]\n",
        "\n",
        "print(\"Accuracy:\", np.round(testing['is_close'].mean(), 2))"
      ],
      "metadata": {
        "id": "hZ8okHpWe36H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}